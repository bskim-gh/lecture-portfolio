# Section 5: ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ

## ğŸ“š í•™ìŠµ ëª©í‘œ
- Scikit-learnì„ ì‚¬ìš©í•œ ì§€ë„í•™ìŠµê³¼ ë¹„ì§€ë„í•™ìŠµ ì´í•´
- íšŒê·€, ë¶„ë¥˜, êµ°ì§‘í™” ë“± ê¸°ë³¸ ì•Œê³ ë¦¬ì¦˜ í•™ìŠµ
- ëª¨ë¸ í‰ê°€ ë° ì„±ëŠ¥ í–¥ìƒ ê¸°ë²• ìŠµë“

---

## 5-1. Scikit-learnì„ ì‚¬ìš©í•œ ì§€ë„í•™ìŠµê³¼ ë¹„ì§€ë„í•™ìŠµ

Scikit-learnì€ íŒŒì´ì¬ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ê°„í¸í•˜ê³  íš¨ê³¼ì ì¸ APIë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### ì§€ë„í•™ìŠµ ì˜ˆì œ: ë¶“ê½ƒ í’ˆì¢… ë¶„ë¥˜

ì§€ë„í•™ìŠµì€ ë ˆì´ë¸”ì´ ìˆëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•˜ê³ , ìƒˆë¡œìš´ ì…ë ¥ ë°ì´í„°ì˜ ë ˆì´ë¸”ì„ ì˜ˆì¸¡í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ë°©ë²•ì…ë‹ˆë‹¤.

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# ë°ì´í„° ë¡œë“œ
iris = load_iris()
X = iris.data
y = iris.target

# ë°ì´í„° ë¶„í•  (Train, Test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# K-Nearest Neighbors ë¶„ë¥˜ ëª¨ë¸ ìƒì„±
knn = KNeighborsClassifier(n_neighbors=3)

# ëª¨ë¸ í•™ìŠµ
knn.fit(X_train, y_train)

# ì˜ˆì¸¡
y_pred = knn.predict(X_test)

# ì •í™•ë„ í‰ê°€
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
```

### ë¹„ì§€ë„í•™ìŠµ ì˜ˆì œ: êµ°ì§‘í™” (K-Means Clustering)

ë¹„ì§€ë„í•™ìŠµì€ ë ˆì´ë¸”ì´ ì—†ëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒ¨í„´ì„ ì°¾ê±°ë‚˜ ë°ì´í„°ë¥¼ ê·¸ë£¹í™”í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ë°©ë²•ì…ë‹ˆë‹¤.

```python
from sklearn.datasets import load_iris
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# ë°ì´í„° ë¡œë“œ
iris = load_iris()
X = iris.data

# K-Means êµ°ì§‘í™” ëª¨ë¸ ìƒì„±
kmeans = KMeans(n_clusters=3, random_state=42)

# ëª¨ë¸ í•™ìŠµ
kmeans.fit(X)

# ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ í´ëŸ¬ìŠ¤í„° í• ë‹¹
labels = kmeans.labels_

# êµ°ì§‘ ì¤‘ì‹¬ í™•ì¸
centers = kmeans.cluster_centers_

# êµ°ì§‘ ê²°ê³¼ ì‹œê°í™”
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='X', s=200)
plt.xlabel('Sepal Length (cm)')
plt.ylabel('Sepal Width (cm)')
plt.title('K-Means Clustering')
plt.show()
```

---

## 5-2. íšŒê·€, ë¶„ë¥˜, êµ°ì§‘í™” ë“± ê¸°ë³¸ ì•Œê³ ë¦¬ì¦˜ í•™ìŠµ

### 1. íšŒê·€(Regression)

íšŒê·€ëŠ” ì—°ì†ì ì¸ ê°’(ì¢…ì† ë³€ìˆ˜)ê³¼ ê·¸ì™€ ê´€ë ¨ëœ íŠ¹ì„±(ë…ë¦½ ë³€ìˆ˜) ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

**ì˜ˆì œ: ë‹¨ìˆœ ì„ í˜• íšŒê·€**

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)
y = np.array([2, 3, 4, 5, 6])

# ì„ í˜• íšŒê·€ ëª¨ë¸ ìƒì„±
model = LinearRegression()

# ëª¨ë¸ í•™ìŠµ
model.fit(X, y)

# ì˜ˆì¸¡
X_test = np.array([6, 7, 8]).reshape(-1, 1)
y_pred = model.predict(X_test)

# ê²°ê³¼ ì‹œê°í™”
plt.scatter(X, y, label='Actual Data')
plt.plot(X_test, y_pred, color='red', label='Regression Line')
plt.xlabel('X')
plt.ylabel('y')
plt.legend()
plt.show()
```

### 2. ë¶„ë¥˜(Classification)

ë¶„ë¥˜ëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ê°œì˜ í´ë˜ìŠ¤ ë˜ëŠ” ë²”ì£¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

**ì˜ˆì œ: ë¡œì§€ìŠ¤í‹± íšŒê·€ (ì´ì§„ ë¶„ë¥˜)**

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression

# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)
y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])

# ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ìƒì„±
model = LogisticRegression()

# ëª¨ë¸ í•™ìŠµ
model.fit(X, y)

# ì˜ˆì¸¡
X_test = np.array([3.5, 7.5]).reshape(-1, 1)
y_pred = model.predict(X_test)

# ê²°ê³¼ ì‹œê°í™”
plt.scatter(X, y, label='Actual Data')
plt.plot(X_test, y_pred, color='red', marker='o', linestyle='dashed', label='Predicted Class')
plt.xlabel('X')
plt.ylabel('Class (0 or 1)')
plt.legend()
plt.show()
```

### 3. êµ°ì§‘í™”(Clustering)

êµ°ì§‘í™”ëŠ” ë ˆì´ë¸”ì´ ì—†ëŠ” ë°ì´í„°ë¥¼ ë¹„ìŠ·í•œ íŠ¹ì„±ì„ ê°€ì§€ëŠ” ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

**ì˜ˆì œ: K-Means êµ°ì§‘í™”**

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
X = np.array([[1, 2], [2, 3], [5, 8], [6, 7], [10, 12], [12, 13]])

# K-Means êµ°ì§‘í™” ëª¨ë¸ ìƒì„±
kmeans = KMeans(n_clusters=2)

# ëª¨ë¸ í•™ìŠµ
kmeans.fit(X)

# ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ í´ëŸ¬ìŠ¤í„° í• ë‹¹
labels = kmeans.labels_

# êµ°ì§‘ ì¤‘ì‹¬ í™•ì¸
centers = kmeans.cluster_centers_

# ê²°ê³¼ ì‹œê°í™”
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', label='Clusters')
plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='X', s=200, label='Centroids')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()
```

---

## 5-3. ëª¨ë¸ í‰ê°€ì™€ ì„±ëŠ¥ í–¥ìƒ

ëª¨ë¸ í‰ê°€ì™€ ì„±ëŠ¥ í–¥ìƒì€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³  ê²°ê³¼ë¥¼ í‰ê°€í•˜ë©°, ë” ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ê¸° ìœ„í•œ ê³¼ì •ì…ë‹ˆë‹¤.

### 1. ëª¨ë¸ í‰ê°€

**ì˜ˆì œ: ë¶„ë¥˜ ëª¨ë¸ì˜ í‰ê°€**

```python
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ
iris = load_iris()
X = iris.data
y = iris.target

# ë°ì´í„° ë¶„í•  (Train, Test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ìƒì„±
model = LogisticRegression()

# ëª¨ë¸ í•™ìŠµ
model.fit(X_train, y_train)

# ì˜ˆì¸¡
y_pred = model.predict(X_test)

# í‰ê°€ ì§€í‘œ ê³„ì‚°
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
conf_matrix = confusion_matrix(y_test, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
print("Confusion Matrix:")
print(conf_matrix)
```

### 2. ì„±ëŠ¥ í–¥ìƒ: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ
iris = load_iris()
X = iris.data
y = iris.target

# ë°ì´í„° ë¶„í•  (Train, Test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ ìƒì„±
model = RandomForestClassifier()

# í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ìœ„í•œ ê·¸ë¦¬ë“œ ì„œì¹˜
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)
grid_search.fit(X_train, y_train)

# ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ì„±ëŠ¥ ì¶œë ¥
print("Best Parameters:", grid_search.best_params_)
print("Best Accuracy:", grid_search.best_score_)

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ í‰ê°€
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Test Accuracy:", accuracy)
```

---

## ğŸ“ ì •ë¦¬

Section 5ì—ì„œëŠ” ë‹¤ìŒ ë‚´ìš©ì„ ë‹¤ë£¨ì—ˆìŠµë‹ˆë‹¤:
- Scikit-learnì„ ì‚¬ìš©í•œ ì§€ë„í•™ìŠµ (K-Nearest Neighbors ë¶„ë¥˜)
- ë¹„ì§€ë„í•™ìŠµ (K-Means êµ°ì§‘í™”)
- íšŒê·€ (Linear Regression), ë¶„ë¥˜ (Logistic Regression), êµ°ì§‘í™” (K-Means)
- ëª¨ë¸ í‰ê°€ ì§€í‘œ: Accuracy, Precision, Recall, F1 Score, Confusion Matrix
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (GridSearchCV)

ë¨¸ì‹ ëŸ¬ë‹ì˜ ê¸°ë³¸ ì•Œê³ ë¦¬ì¦˜ê³¼ í‰ê°€ ë°©ë²•ì„ ì´í•´í•˜ë©´ ë‹¤ì–‘í•œ ë°ì´í„° ë¶„ì„ ë° ì˜ˆì¸¡ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

